try:
    import streamlit as st
except ModuleNotFoundError:
    raise ModuleNotFoundError("This script requires the 'streamlit' package. Please install it using 'pip install streamlit'")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier

# Dummy model training (to be replaced with actual model persistence in real use)
def train_model():
    np.random.seed(42)
    n_samples = 1000
    data = {
        "Temperature_C": np.random.normal(25, 1.5, n_samples),
        "Pressure_bar": np.random.normal(1.0, 0.05, n_samples),
        "MixingSpeed_rpm": np.random.normal(120, 10, n_samples),
        "pH": np.random.normal(7.0, 0.3, n_samples),
        "Yield_percent": np.random.normal(95, 2, n_samples),
        "Contaminant_ppm": np.random.exponential(1.0, n_samples),
    }
    df = pd.DataFrame(data)
    df['Defective'] = ((df['Yield_percent'] < 92) | (df['Contaminant_ppm'] > 5)).astype(int)

    X = df.drop(columns='Defective')
    y = df['Defective']
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)
    return model, X.columns.tolist(), model.feature_importances_

# Train model and retrieve feature importances
model, feature_names, feature_importances = train_model()

# Streamlit App
st.title("ì˜ì•½í’ˆ ìƒì‚° ë°°ì¹˜ ë¶ˆëŸ‰ ì˜ˆì¸¡ íˆ´")
st.write("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ê° ë°°ì¹˜ì˜ ë¶ˆëŸ‰ ì—¬ë¶€ì™€ ì˜ˆì¸¡ í™•ë¥ ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")

uploaded_file = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded_file is not None:
    input_df = pd.read_csv(uploaded_file)
    required_columns = ["Temperature_C", "Pressure_bar", "MixingSpeed_rpm", "pH", "Yield_percent", "Contaminant_ppm"]

    if all(col in input_df.columns for col in required_columns):
        proba = model.predict_proba(input_df[required_columns])[:, 1]
        predictions = model.predict(input_df[required_columns])
        input_df['Predicted_Defective'] = predictions
        input_df['Defect_Probability_%'] = (proba * 100).round(2)

        st.success("ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ë¥¼ ì•„ë˜ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
        st.dataframe(input_df)

        csv = input_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name='prediction_results.csv',
            mime='text/csv',
        )

        # Feature importance plot
        st.subheader("ğŸ“Š ì£¼ìš” ë³€ìˆ˜ ì¤‘ìš”ë„")
        importance_df = pd.DataFrame({
            "Feature": feature_names,
            "Importance": feature_importances
        }).sort_values(by="Importance", ascending=True)

        fig, ax = plt.subplots(figsize=(8, 5))
        sns.barplot(x="Importance", y="Feature", data=importance_df, ax=ax)
        ax.set_title("Feature Importances")
        st.pyplot(fig)

    else:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {required_columns}")
else:
    st.info("ì˜ˆì¸¡ì„ ì‹œì‘í•˜ë ¤ë©´ ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# Deployment Info
st.markdown("""
---
### â˜ï¸ ë°°í¬ ì•ˆë‚´
- **Streamlit Cloud**:
  - [https://streamlit.io/cloud](https://streamlit.io/cloud) ì—ì„œ GitHubì™€ ì—°ë™í•´ ë°”ë¡œ ë°°í¬ ê°€ëŠ¥
  - ì´ ì½”ë“œë¥¼ `kodaehong_batch_defect_predictor.py`ë¡œ ì €ì¥ í›„ GitHub ì €ì¥ì†Œì— ì˜¬ë¦¬ê³  Streamlit Cloudì—ì„œ ì—°ê²°í•˜ë©´ ë!

- **AWS EC2 / Lightsail**:
  - ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„ Python, pip ì„¤ì¹˜
  - ë³¸ íŒŒì¼ ì—…ë¡œë“œ í›„ `streamlit run kodaehong_batch_defect_predictor.py`ë¡œ ì‹¤í–‰
  - `nohup`, `tmux`, `screen` ë“±ìœ¼ë¡œ ì„œë²„ ìœ ì§€ ê°€ëŠ¥

ë°°í¬ì— ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ì§ˆë¬¸ ì£¼ì„¸ìš”!
""")

